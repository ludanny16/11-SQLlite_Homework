{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CSV file\n",
    "csvfile = \"cleaned_hawaii_measurements.csv\"\n",
    "csvfile2 = \"cleaned_hawaii_stations.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(csvfile, dtype=object)\n",
    "df2 = pd.read_csv(csvfile2, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Python SQL toolkit and Object Relational Mapper\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine, MetaData\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy import Column, Integer, String, Numeric, Text, Float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create an engine to a database file called `hawaii.sqlite`\n",
    "engine = create_engine(\"sqlite:///hawaii.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a connection to the engine called `conn`\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use `declarative_base` from SQLAlchemy to model the demographics table as an ORM class\n",
    "# specify types for each column\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "class Measurement(Base):\n",
    "    \n",
    "    __tablename__ = 'measurement'\n",
    "\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    station = Column(Text)\n",
    "    date = Column(Text)\n",
    "    prcp = Column(Float)\n",
    "    tobs = Column(Float)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"id={self.id}, name={self.station}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use `declarative_base` from SQLAlchemy to model the demographics table as an ORM class\n",
    "# specify types for each column\n",
    "\n",
    "\n",
    "class Station(Base):\n",
    "\n",
    "    __tablename__ = 'station'\n",
    "\n",
    "    station = Column(String, primary_key=True)\n",
    "    name = Column(String)\n",
    "    latitude = Column(Float)\n",
    "    longitude = Column(Float)\n",
    "    elevation = Column(Float)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"id={self.id}, name={self.station}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use `create_all` to create the demographics table in the database\n",
    "Base.metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned csv file into a pandas dataframe\n",
    "df_of_data_to_insert = pd.read_csv(csvfile)\n",
    "df_of_data_to_insert2 = pd.read_csv(csvfile2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date': '2010-01-01', 'prcp': 0.08, 'station': 'USC00519397', 'tobs': 65}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use Orient='records' to create a list of data to write\n",
    "data = df_of_data_to_insert.to_dict(orient='records')\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'elevation': 3.0,\n",
       " 'latitude': 21.2716,\n",
       " 'longitude': -157.8168,\n",
       " 'station': 'USC00519397'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = df_of_data_to_insert2.to_dict(orient='records')\n",
    "data2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use MetaData from SQLAlchemy to reflect the tables\n",
    "metadata = MetaData(bind=engine)\n",
    "metadata.reflect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the reference to the `hawaii` table as a variable called `table`\n",
    "table = sqlalchemy.Table('measurement', metadata, autoload=True)\n",
    "table2 = sqlalchemy.Table('station', metadata, autoload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.result.ResultProxy at 0x1082f15c0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use `table.delete()` to remove any existing data.\n",
    "conn.execute(table.delete())\n",
    "conn.execute(table2.delete())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.result.ResultProxy at 0x108f5cf60>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use `table.insert()` to insert the data into the table\n",
    "conn.execute(table.insert(), data)\n",
    "conn.execute(table2.insert(), data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'USC00519397', '2010-01-01', 0.08, 65.0),\n",
       " (2, 'USC00519397', '2010-01-02', 0.0, 63.0),\n",
       " (3, 'USC00519397', '2010-01-03', 0.0, 74.0),\n",
       " (4, 'USC00519397', '2010-01-04', 0.0, 76.0),\n",
       " (5, 'USC00519397', '2010-01-07', 0.06, 70.0)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test that the insert works by fetching the first 5 rows. \n",
    "conn.execute(\"select * from measurement limit 5\").fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('USC00519397', None, 21.2716, -157.8168, 3.0),\n",
       " ('USC00513117', None, 21.4234, -157.8015, 14.6),\n",
       " ('USC00514830', None, 21.5213, -157.8374, 7.0),\n",
       " ('USC00517948', None, 21.3934, -157.9751, 11.9),\n",
       " ('USC00518838', None, 21.4992, -158.0111, 306.6)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test that the insert works by fetching the first 5 rows. \n",
    "conn.execute(\"select * from station limit 5\").fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
